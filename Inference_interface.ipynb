{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train' from '/Users/lucasmoeller/Documents/BirdsOnMars/GitHub/birdsonearth/birdsonearth/train.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imp\n",
    "import train\n",
    "import predict\n",
    "from utils import preprocessing as pre\n",
    "import params as p\n",
    "imp.reload(p)\n",
    "imp.reload(predict)\n",
    "imp.reload(pre)\n",
    "imp.reload(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for inference\n",
    "\n",
    "Define some parameters relevant for inference:\n",
    "\n",
    "- `params.name` is the model to be loaded\n",
    "- `params.device` is the device used for all calculations, set it to `'cuda:<device index>'` if you have access to an nvidia GPU, and to `'cpu'` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = p.Params()\n",
    "\n",
    "params.name = 'birds10'\n",
    "params.device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files\n",
    "\n",
    "put some files into the list below that you want predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['data/Columba.wav', 'data/Parus.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "\n",
    "Next the model specified by `params.name` loaded to the device given by `params.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "model for labels ['Coloeus', 'Columba', 'Erithacus', 'Garrulus', 'Parus', 'Passer', 'Pica', 'Picoides', 'Sturnus', 'Turdus'] is ready\n"
     ]
    }
   ],
   "source": [
    "model, labels = predict.load_model_with(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "For inference the files are resampled to the needed sampling rate of 22050 Hz.\n",
    "Subsequently they are cut into pieces and a spectrograms are computed from each piece. \n",
    "All spectrogram are fed through the network and the resulting predictions are averaged over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasmoeller/Documents/BirdsOnMars/GitHub/birdsonearth/birdsonearth/VGGish_model.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = softmax(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 0 sound like a Columba to me\n",
      "my guesses are: \n",
      "Coloeus: 0.0136\n",
      "Columba: 0.8373\n",
      "Erithacus: 0.0001\n",
      "Garrulus: 0.0417\n",
      "Parus: 0.0079\n",
      "Passer: 0.0090\n",
      "Pica: 0.0381\n",
      "Picoides: 0.0248\n",
      "Sturnus: 0.0263\n",
      "Turdus: 0.0012\n",
      "file 1 sound like a Parus to me\n",
      "my guesses are: \n",
      "Coloeus: 0.0618\n",
      "Columba: 0.0036\n",
      "Erithacus: 0.1668\n",
      "Garrulus: 0.0629\n",
      "Parus: 0.3254\n",
      "Passer: 0.2317\n",
      "Pica: 0.0815\n",
      "Picoides: 0.0142\n",
      "Sturnus: 0.0335\n",
      "Turdus: 0.0185\n"
     ]
    }
   ],
   "source": [
    "predictions, probs = predict.predict(model, labels, files, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
